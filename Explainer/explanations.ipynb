{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we work with look-up tables that were created for Section 4.3 to compute Shapley values for the four CatBoost models from Section 4.2 which were trained on public datasets. A sample of size 100 from the test set is provided in each case, and is available in the folder `Samples`. \n",
    "\n",
    "The look-up tables were created via a proprietary code of Discover Financial Services which is a fast implementation of Algorithm 3.12. These are located in folders `Shapley_values_loc_1`, `Shapley_values_loc_2` etc. where there is a `.csv` file for each tree of the ensemble under consideration containing all Shapley values arising from that tree. The rows are indexed by the leaves of the oblivious tree and the columns capture the features on which the tree splits. The non-realizable leaves corresponding to vacuous regions are excluded. The `.json` file in each folder relates the local enumeration of features appearing in a tree to their global index in the training data. \n",
    "\n",
    "We verify these precomputed Shapley values through checking the \n",
    "[efficiency axiom](https://christophm.github.io/interpretable-ml-book/shapley.html#the-shapley-value-in-detail): Choosing a tree from one of the four ensembles randomly, for each data sample, the difference between tree's output (i.e. the leaf value) and the sum of Shapley values associated with the corresponding leaf is always a constantâ€”it should be equal to the average of outputs of that tree over the whole training data:\n",
    "\n",
    "$$\\sum_i\\varphi_i[g](\\mathbf{x})=g(\\mathbf{x})-\\mathbb{E}[g]\\quad \\forall\\mathbf{x}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T20:41:57.960223Z",
     "iopub.status.busy": "2023-08-05T20:41:57.959828Z",
     "iopub.status.idle": "2023-08-05T20:42:08.928501Z",
     "shell.execute_reply": "2023-08-05T20:42:08.927896Z",
     "shell.execute_reply.started": "2023-08-05T20:41:57.960153Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load the CatBoost model and the corresponding data sample. Only `experiment_number` should be declared (a number between 1 and 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T20:44:27.016910Z",
     "iopub.status.busy": "2023-08-05T20:44:27.016199Z",
     "iopub.status.idle": "2023-08-05T20:44:27.550671Z",
     "shell.execute_reply": "2023-08-05T20:44:27.549977Z",
     "shell.execute_reply.started": "2023-08-05T20:44:27.016882Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We consider the CatBoost ensemble from experiment 4 which has 1000 trees.\n"
     ]
    }
   ],
   "source": [
    "experiment_number=4\n",
    "\n",
    "if experiment_number==1 or experiment_number==2:\n",
    "    model_type='Regressor'\n",
    "elif experiment_number==3 or experiment_number==4:\n",
    "    model_type='Classifier'\n",
    "else:\n",
    "    raise ValueError('experiment_number should be 1,2,3 or 4.')\n",
    "    \n",
    "sample_path='./Samples/Sample_'+str(experiment_number)+'.csv'\n",
    "sample=pd.read_csv(sample_path)\n",
    "n_samples=sample.shape[0]\n",
    "\n",
    "model_path='./Models/'+model_type+'_CatBoost_'+str(experiment_number)\n",
    "model_cat=pickle.load(open(model_path,'rb'))\n",
    "\n",
    "local_shapley_folder_path='./Shapley_values_loc_'+str(experiment_number)\n",
    "n_trees=len(glob.glob1(local_shapley_folder_path,'*.csv'))\n",
    "print(f'We consider the CatBoost ensemble from experiment {experiment_number} which has {n_trees} trees.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already have a script `EnsembleParser.py` for deriving various statistics from a trained CatBoost ensemble. Below, we import this library to compute averages of leaf values which we shall need for our efficiency test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import EnsembleParser\n",
    "from EnsembleParser import Parser\n",
    "averages=Parser(model_cat).tree_average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-05T20:44:37.008525Z",
     "iopub.status.busy": "2023-08-05T20:44:37.008227Z",
     "iopub.status.idle": "2023-08-05T20:44:37.521443Z",
     "shell.execute_reply": "2023-08-05T20:44:37.520885Z",
     "shell.execute_reply.started": "2023-08-05T20:44:37.008504Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tree of index 182 was chosen randomly from the CatBoost ensemble.\n",
      "The average of its outputs over the training data is -8.096037103613889e-05.\n",
      "\n",
      "Verifying the efficiency axiom: the output minus the sum of local Shapley values should be the same for all 100 sample data points; this difference always coincides with the average output of the tree.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05,\n",
       "       -8.0960371e-05, -8.0960371e-05, -8.0960371e-05, -8.0960371e-05])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We pick a random tree. Since leaves corresponding to degenerate regions are not considered in look-up tables, \n",
    "#we only consider tables with (number of rows)=2**(number of columns), that is, trees without repeated features. \n",
    "#For such trees, the internal enumeration of leaves matches the order of rows. \n",
    "\n",
    "while True:\n",
    "    tree_index=random.randint(0,n_trees-1)\n",
    "    local_shapley=pd.read_csv(local_shapley_folder_path+'/game_value_tree_'+str(tree_index)+'.csv',\n",
    "                         header=None)\n",
    "    if local_shapley.shape[0]==2**(local_shapley.shape[1]):\n",
    "        break\n",
    "print(f'The tree of index {tree_index} was chosen randomly from the CatBoost ensemble.')\n",
    "print(f'The average of its outputs over the training data is {averages[tree_index]}.')\n",
    "        \n",
    "#The outputs of the chosen tree at the sample points. These are leaf values (logit probability values in the case of classifiers).         \n",
    "outputs=model_cat.predict(sample,prediction_type='RawFormulaVal',\n",
    "                          ntree_start=tree_index,ntree_end=tree_index+1)\n",
    "        \n",
    "\n",
    "#Determining leaves of the tree at which sample points land:\n",
    "leaf_indices=model_cat.calc_leaf_indexes(sample,ntree_start=tree_index,ntree_end=tree_index+1).reshape(n_samples)\n",
    "\n",
    "#Adding the sum of rows to the table of Shapley values\n",
    "local_shapley['sum']=local_shapley.sum(axis=1)\n",
    "\n",
    "#Subtracting the sum of Shapley values at the leaf corresponding to a sample point from the leaf value:\n",
    "difference=outputs-np.asarray(local_shapley['sum'][leaf_indices].to_list())\n",
    "print(f'\\nVerifying the efficiency axiom: the output minus the sum of local Shapley values should be the same for all {n_samples} sample data points; this difference always coincides with the average output of the tree.')\n",
    "difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the efficiency axiom can be confirmed for Owen values. For the same models, and for appropriate partitions of their respective features (check folder `MIC_based_grouping`), we have generated look-up tables of Owen values based on a proprietary implementation of Theorem F.1. The tables are saved in folders `Owen_values_loc_1`, `Owen_values_loc_2` etc. which have the same structure: a `.csv` file for each tree recording the Owen values at its (realizable) leaves for the features on which the tree splits along with a `.json` file capturing features relevant to each tree, their global indices (and the partition in hand).\n",
    "\n",
    "These precomputed Owen values are verified, again, through checking the \n",
    "[efficiency axiom](https://christophm.github.io/interpretable-ml-book/shapley.html#the-shapley-value-in-detail): Choosing a tree from one of the four ensembles randomly, for each data sample, the difference between tree's output (i.e. the leaf value) and the sum of Owen values associated with the corresponding leaf is always a constantâ€”it should be equal to the average of outputs of that tree over the whole training data:\n",
    "\n",
    "$$\\sum_iOw_i[g](\\mathbf{x})=g(\\mathbf{x})-\\mathbb{E}[g]\\quad \\forall\\mathbf{x}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tree of index 217 was chosen randomly from the CatBoost ensemble.\n",
      "The average of its outputs over the training data is -3.341477025607011e-05.\n",
      "\n",
      "Verifying the efficiency axiom: the output minus the sum of local Owen values should be the same for all 100 sample data points; this difference always coincides with the average output of the tree..\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05,\n",
       "       -3.34147703e-05, -3.34147703e-05, -3.34147703e-05, -3.34147703e-05])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We pick a random tree. Since leaves corresponding to degenerate regions are not considered in look-up tables, \n",
    "#we only consider tables with (number of rows)=2**(number of columns), that is, trees without repeated features. \n",
    "#For such trees, the internal enumeration of leaves matches the order of rows. \n",
    "\n",
    "local_owen_folder_path='./Owen_values_loc_'+str(experiment_number)\n",
    "\n",
    "while True:\n",
    "    tree_index=random.randint(0,n_trees-1)\n",
    "    local_owen=pd.read_csv(local_owen_folder_path+'/game_value_tree_'+str(tree_index)+'.csv',\n",
    "                         header=None)\n",
    "    if local_owen.shape[0]==2**(local_owen.shape[1]):\n",
    "        break\n",
    "print(f'The tree of index {tree_index} was chosen randomly from the CatBoost ensemble.')\n",
    "print(f'The average of its outputs over the training data is {averages[tree_index]}.')\n",
    "        \n",
    "#The outputs of the chosen tree at the sample points. These are leaf values (logit probability values in the case of classifiers).        \n",
    "outputs=model_cat.predict(sample,prediction_type='RawFormulaVal',\n",
    "                          ntree_start=tree_index,ntree_end=tree_index+1)\n",
    "        \n",
    "\n",
    "#Determining leaves of the tree at which sample points land:\n",
    "leaf_indices=model_cat.calc_leaf_indexes(sample,ntree_start=tree_index,ntree_end=tree_index+1).reshape(n_samples)\n",
    "\n",
    "#Adding the sum of rows to the table of Owen values\n",
    "local_owen['sum']=local_owen.sum(axis=1)\n",
    "\n",
    "#Subtracting the sum of Shapley values at the leaf corresponding to a sample point from the leaf value:\n",
    "difference=outputs-np.asarray(local_owen['sum'][leaf_indices].to_list())\n",
    "print(f'\\nVerifying the efficiency axiom: the output minus the sum of local Owen values should be the same for all {n_samples} sample data points; this difference always coincides with the average output of the tree..')\n",
    "difference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
